{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instally Snowflake and making the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyarrow==10.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake-connector-python\n",
      "  Using cached snowflake_connector_python-3.12.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (64 kB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python)\n",
      "  Using cached asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (42.0.8)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (24.2.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2024.1)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.32.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2024.7.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (4.12.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.15.4)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (4.2.2)\n",
      "Collecting tomlkit (from snowflake-connector-python)\n",
      "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0->snowflake-connector-python) (1.26.19)\n",
      "Using cached snowflake_connector_python-3.12.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (2.5 MB)\n",
      "Using cached asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: asn1crypto, tomlkit, snowflake-connector-python\n",
      "Successfully installed asn1crypto-1.5.1 snowflake-connector-python-3.12.1 tomlkit-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = snowflake.connector.connect(\n",
    "    user='SIDDHARTHAMYSORE',\n",
    "    password='Fall@2024',\n",
    "    account='luqhchh-xnb07739',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Warehouse, database, schema and Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE WAREHOUSE IF NOT EXISTS ETL_Group_2_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE DATABASE IF NOT EXISTS ELT_Project_Database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE SCHEMA IF NOT EXISTS CSV_Schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE OR REPLACE STAGE CSV_Stage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and load the 41 comma delimited purchases data files\n",
    "and form a single table of purchases data; a. Preferably follow these guidelines when staging the files (this staging approach does not make sense for our data as the files are small, but it is good practice if you have more data and if the data is loaded over time) b. Use Python to automate the PUT process, e.g., use glob to iterate through and PUT all purchases files automatically c. COPY INTO is generally preferred over INSERT INTO (this applies to the entire project); d. To the extent possible, perform transformations such as selecting columns and setting data types during the COPY INTO process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a table called \"MonthlyPurchaseOrders\" to load the 41 csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE MonthlyPurchaseOrders (\n",
    "        PurchaseOrderID INT,\n",
    "        SupplierID INT,\n",
    "        OrderDate DATE,\n",
    "        DeliveryMethodID INT,\n",
    "        ContactPersonID INT,\n",
    "        ExpectedDeliveryDate DATE,\n",
    "        SupplierReference VARCHAR(255),\n",
    "        IsOrderFinalized BOOLEAN,\n",
    "        Comments VARCHAR,\n",
    "        InternalComments VARCHAR,\n",
    "        LastEditedBy INT,\n",
    "        LastEditedWhen TIMESTAMP,\n",
    "        PurchaseOrderLineID INT,\n",
    "        StockItemID INT,\n",
    "        OrderedOuters INT,\n",
    "        Description VARCHAR,\n",
    "        ReceivedOuters INT,\n",
    "        PackageTypeID INT,\n",
    "        ExpectedUnitPricePerOuter FLOAT,\n",
    "        LastReceiptDate DATE,\n",
    "        IsOrderLineFinalized BOOLEAN,\n",
    "        Right_LastEditedBy INT,\n",
    "        Right_LastEditedWhen TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Glob to load all the csv files at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"/home/jovyan/etl/Monthly_PO_Data/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Staging the files to the stage called \"CSV_Stage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in files:\n",
    "    put_command = f\"PUT file://{file_path} @CSV_stage\"\n",
    "    cs.execute(put_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying the csv files to the MonthlyPurchaseOrder table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All staged files have been loaded into 'MonthlyPurchaseOrders'.\n"
     ]
    }
   ],
   "source": [
    "copy_command = \"\"\"\n",
    "COPY INTO MonthlyPurchaseOrders\n",
    "FROM @CSV_stage\n",
    "FILE_FORMAT = (\n",
    "    TYPE = 'CSV'\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY='\"'\n",
    "    SKIP_HEADER=1\n",
    "    TIMESTAMP_FORMAT = 'MM/DD/YYYY HH:MI'\n",
    "    DATE_FORMAT = 'MM/DD/YYYY'\n",
    "    NULL_IF = ('NULL', '00:00.0', '2/29/2022', '2/28/2022 7:00:00 AM')\n",
    ")\n",
    "ON_ERROR = 'CONTINUE';\n",
    "\"\"\"\n",
    "cs.execute(copy_command)\n",
    "print(\"All staged files have been loaded into 'MonthlyPurchaseOrders'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "ALTER TABLE MonthlyPurchaseOrders\n",
    "ADD COLUMN POAmount DECIMAL(18, 2);\n",
    "\"\"\"\n",
    "cs.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating a calculated field that shows purchase order totals,\n",
    "i.e., for each order, sum the line item amounts (defined as ReceivedOuters * ExpectedUnitPricePerOuter), and name this field POAmount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "UPDATE MonthlyPurchaseOrders\n",
    "SET POAmount = (\n",
    "    SELECT SUM(p.ReceivedOuters * p.ExpectedUnitPricePerOuter)\n",
    "    FROM MonthlyPurchaseOrders p\n",
    "    WHERE p.PurchaseOrderID = MonthlyPurchaseOrders.PurchaseOrderID\n",
    ");\n",
    "\"\"\"\n",
    "cs.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract and Load Supplier invoice data\n",
    "shred the data into a table (preferably in the COPY INTO process) where each row corresponds to a single invoicevoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE OR REPLACE STAGE XML_Stage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getcwd() + \"/SupplierTransactionsXML.xml\"\n",
    "stage_name = \"XML_Stage\"\n",
    "put_command = f\"PUT file://{file_path} @{stage_name}\"\n",
    "cs.execute(put_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table_command = \"\"\"CREATE OR REPLACE TABLE SupplierTransactions(xml_data VARIANT NOT NULL);\"\"\"\n",
    "cs.execute(create_table_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy= f\"\"\" COPY INTO SupplierTransactions FROM @XML_stage FILE_FORMAT = (TYPE = 'XML') ON_ERROR='CONTINUE';\"\"\"\n",
    "cs.execute(copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Table SUPPLIERTRANSACTIONS successfully created.',)\n"
     ]
    }
   ],
   "source": [
    "cs.execute(\"\"\" \n",
    "CREATE OR REPLACE TABLE SupplierTransactions AS\n",
    "SELECT\n",
    "    XMLGET( r.value, 'SupplierTransactionID' ):\"$\"::INTEGER AS SupplierTransactionID,\n",
    "    XMLGET( r.value, 'SupplierID' ):\"$\"::INTEGER AS SupplierID,\n",
    "    XMLGET( r.value, 'TransactionTypeID' ):\"$\"::INTEGER AS TransactionTypeID,\n",
    "    CASE WHEN REGEXP_LIKE(XMLGET(r.value, 'PurchaseOrderID'):\"$\", '^[0-9]+$') THEN TO_NUMBER(XMLGET(r.value, 'PurchaseOrderID'):\"$\") ELSE NULL END AS PurchaseOrderID,\n",
    "    XMLGET( r.value, 'PaymentMethodID' ):\"$\"::INTEGER AS PaymentMethodID,\n",
    "    CASE WHEN REGEXP_LIKE(XMLGET(r.value, 'SupplierInvoiceNumber'):\"$\", '^[0-9]+$') THEN TO_NUMBER(XMLGET(r.value, 'SupplierInvoiceNumber'):\"$\") ELSE NULL END AS SupplierInvoiceNumber,\n",
    "    XMLGET( r.value, 'TransactionDate' ):\"$\"::STRING AS TransactionDate,\n",
    "    XMLGET( r.value, 'AmountExcludingTax' ):\"$\"::FLOAT AS AmountExcludingTax,\n",
    "    XMLGET( r.value, 'TaxAmount' ):\"$\"::FLOAT AS TaxAmount,\n",
    "    XMLGET( r.value, 'TransactionAmount' ):\"$\"::FLOAT AS TransactionAmount,\n",
    "    XMLGET( r.value, 'OutstandingBalance' ):\"$\"::FLOAT AS OutstandingBalance,\n",
    "    XMLGET( r.value, 'FinalizationDate' ):\"$\"::STRING AS FinalizationDate,\n",
    "    XMLGET( r.value, 'IsFinalized' ):\"$\"::INTEGER AS IsFinalized,\n",
    "    XMLGET( r.value, 'LastEditedBy' ):\"$\"::INTEGER AS LastEditedBy,\n",
    "    XMLGET( r.value, 'LastEditedWhen' ):\"$\"::STRING AS LastEditedWhen\n",
    "FROM SupplierTransactions,  \n",
    "LATERAL FLATTEN(SupplierTransactions.xml_data:\"$\") r\n",
    "WHERE GET( r.value, '@') = 'row' \"\"\")\n",
    "\n",
    "rows = cs.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Join the purchases data from step 2 and the supplier invoices data\n",
    "(only include matching rows); assuming that step 2 was completed correctly, you can assume the following relationships among the four tables (the other two tables are discussed below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff662f5e50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE TABLE Supplier_Purchases AS\n",
    "SELECT a.Purchaseorderid, a.supplierid, a.orderdate, a.EXPECTEDDELIVERYDATE, a.ISORDERLINEFINALIZED, a.PURCHASEORDERLINEID, a.STOCKITEMID, \n",
    "a.ORDEREDOUTERS, a.RECEIVEDOUTERS, a.EXPECTEDUNITPRICEPEROUTER, a.LASTRECEIPTDATE, a.POAMOUNT, b.SUPPLIERTRANSACTIONID, b.SUPPLIERINVOICENUMBER, \n",
    "b.TRANSACTIONDATE, b.AMOUNTEXCLUDINGTAX, b.TAXAMOUNT, TRANSACTIONAMOUNT, b.FINALIZATIONDATE\n",
    "FROM MonthlyPurchaseOrders a\n",
    "INNER JOIN SupplierTransactions b on a.supplierid = b.supplierid and a.PURCHASEORDERID = b.PURCHASEORDERID\n",
    "\"\"\"\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create a calculated field that shows the difference between AmountExcludingTax and POAmount\n",
    "Name this field invoiced_vs_quoted, and save the result as a materialized view named purchase_orders_and_invoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff57bacb90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE VIEW PURCHASE_ORDERS_AND_INVOICES AS (\n",
    "SELECT AMOUNTEXCLUDINGTAX, POAMOUNT, (AMOUNTEXCLUDINGTAX - POAMOUNT) AS invoiced_vs_quoted\n",
    "FROM Supplier_Purchases\n",
    ")\n",
    "\"\"\"\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n",
      "[(1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1171782.0, Decimal('410124.00'), 761658.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0), (1118178.0, Decimal('391332.00'), 726846.0)]\n"
     ]
    }
   ],
   "source": [
    "cs.execute(\"select * from PURCHASE_ORDERS_AND_INVOICES order by invoiced_vs_quoted desc limit 10\")\n",
    "rows = cs.fetchmany(10)\n",
    "for row in rows:\n",
    "    print(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extract the supplier_case data from postgres\n",
    "- Consider creating a Python function that can take a csv file path as input and then generate field definitions (field names and datatypes based on the header and data types in the file) that can then be used in CREATE TABLE statement.\n",
    "\n",
    "- You need to use psycopg2 or a similar Python library to connect to the postgres database within Python, issue a command to postgres to have postgres save the supplier_case data to file, and then use cs.execute to move the file to an internal Snowflake stage and eventually into a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"WestCoastImporters\",\n",
    "    user=\"jovyan\",  # The existing superuser\n",
    "    password=\"postgres\",  # The password for the postgres user\n",
    "    host=\"127.0.0.1\",  # Or the IP address of your PostgreSQL server\n",
    "    port=\"8765\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = conn.cursor()\n",
    "directory = os.getcwd()\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Now define the full path for the CSV file\n",
    "csv_file_path = os.path.join(directory, 'supplier_case.csv')\n",
    "\n",
    "query = \"COPY (SELECT * FROM supplier_case) TO STDOUT WITH CSV HEADER\"\n",
    "with open(csv_file_path, 'w') as f:\n",
    "    cs.copy_expert(query, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff57bacb90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"Use database ELT_Project_Database \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff57bacb90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE OR REPLACE STAGE Csv_Stage_Supplier_Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff57bacb90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"USE SCHEMA CSV_SCHEMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff57bacb90>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = os.getcwd() + \"/supplier_case.csv\"\n",
    "cs.execute(f\"PUT file://{csv_file} @Csv_Stage_Supplier_Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff57bacb90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT SUPPLIER_CASE \n",
    "    TYPE = CSV,\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"',\n",
    "    PARSE_HEADER = TRUE,\n",
    "    TIMESTAMP_FORMAT = 'MM/DD/YYYY HH24:MM',\n",
    "\"\"\"\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff57bacb90>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "    CREATE TABLE supplier_case (\n",
    "    supplierid INT,\n",
    "    suppliername VARCHAR(255),\n",
    "    suppliercategoryid INT,\n",
    "    primarycontactpersonid INT,\n",
    "    alternatecontactpersonid INT,\n",
    "    deliverymethodid INT,\n",
    "    postalcityid INT,\n",
    "    supplierreference VARCHAR(50),\n",
    "    bankaccountname VARCHAR(255),\n",
    "    bankaccountbranch VARCHAR(255),\n",
    "    bankaccountcode VARCHAR(50),\n",
    "    bankaccountnumber VARCHAR(50),\n",
    "    bankinternationalcode VARCHAR(50),\n",
    "    paymentdays INT,\n",
    "    internalcomments TEXT,\n",
    "    phonenumber VARCHAR(50),\n",
    "    faxnumber VARCHAR(50),\n",
    "    websiteurl VARCHAR(255),\n",
    "    deliveryaddressline1 VARCHAR(255),\n",
    "    deliveryaddressline2 VARCHAR(255),\n",
    "    deliverypostalcode VARCHAR(20),\n",
    "    deliverylocation VARCHAR(255),\n",
    "    postaladdressline1 VARCHAR(255),\n",
    "    postaladdressline2 VARCHAR(255),\n",
    "    postalpostalcode VARCHAR(20),\n",
    "    lasteditedby INT,\n",
    "    validfrom VARCHAR(50),\n",
    "    validto VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff57bacb90>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "    COPY INTO supplier_case FROM @Csv_Stage_Supplier_Base\n",
    "        FILE_FORMAT = SUPPLIER_CASE\n",
    "        MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE\n",
    "    ON_ERROR = 'CONTINUE'\n",
    "\"\"\"\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Connect manually to NOAA data using Marketplace and work on the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"USE DATABASE ELT_PROJECT_DATABASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"USE SCHEMA CSV_SCHEMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"CREATE STAGE zip_codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = os.getcwd() + \"/2021_Gaz_zcta_national.txt\"\n",
    "\n",
    "cs.execute(f\"PUT file://{file} @zip_codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"\"\"CREATE OR REPLACE TABLE zcta_national (\n",
    "    GEOID VARCHAR(5),\n",
    "    ALAND NUMERIC,\n",
    "    AWATER NUMERIC,\n",
    "    ALAND_SQMI FLOAT,\n",
    "    AWATER_SQMI FLOAT,\n",
    "    INTPTLAT FLOAT,\n",
    "    INTPTLONG FLOAT\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "COPY INTO zcta_national\n",
    "FROM @zip_codes\n",
    "FILE_FORMAT = (\n",
    "    TYPE = 'CSV',\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"',\n",
    "    FIELD_DELIMITER = '\\t',\n",
    "    SKIP_HEADER = 1\n",
    ")\n",
    "\"\"\"\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "    CREATE OR REPLACE TABLE SUPPLIER_ZIP AS (\n",
    "        SELECT a.postalpostalcode, b.INTPTLAT AS LATITUDE, b.INTPTLONG AS LONGITUDE\n",
    "        FROM supplier_case a\n",
    "        JOIN zcta_national b ON a.postalpostalcode = b.GEOID\n",
    "        GROUP BY a.postalpostalcode, b.INTPTLAT, b.INTPTLONG);\n",
    "\"\"\"\n",
    "\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE TABLE zip_weather AS\n",
    "    SELECT \n",
    "        a.postalpostalcode,\n",
    "        b.noaa_weather_station_id AS StationID,\n",
    "        b.noaa_weather_station_name AS StationName,\n",
    "        SQRT(\n",
    "            POW(69.1 * (a.latitude - b.latitude), 2) +\n",
    "            POW(69.1 * (b.longitude - a.longitude) * COS(a.latitude / 57.3), 2)\n",
    "        ) AS distance\n",
    "    FROM ELT_PROJECT_DATABASE.CSV_SCHEMA.SUPPLIER_ZIP a\n",
    "    CROSS JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_station_index b\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY a.postalpostalcode ORDER BY distance ASC) = 1;\n",
    "\"\"\"\n",
    "\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE TABLE zip_weather_data AS\n",
    "           SELECT \n",
    "            a.postalpostalcode,\n",
    "            b.date,\n",
    "            b.value as Max_Temp,\n",
    "            b.variable\n",
    "            FROM ELT_PROJECT_DATABASE.CSV_SCHEMA.zip_weather a\n",
    "            JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_metrics_timeseries b\n",
    "            ON a.STATIONID = b.noaa_weather_station_id\n",
    "            WHERE b.variable = 'maximum_temperature';\n",
    "\"\"\"\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE TABLE zip_weather_station_mapping_temp AS\n",
    "    SELECT \n",
    "        a.postalpostalcode,\n",
    "        b.noaa_weather_station_id AS station_id,\n",
    "        b.noaa_weather_station_name AS station_name,\n",
    "        st_distance(\n",
    "            st_makepoint(a.longitude, b.latitude),\n",
    "            st_makepoint(b.longitude, a.latitude)\n",
    "        ) AS distance\n",
    "    FROM ELT_PROJECT_DATABASE.CSV_SCHEMA.SUPPLIER_ZIP a\n",
    "    JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_station_index b\n",
    "    ON st_distance(st_makepoint(a.longitude, a.latitude), st_makepoint(b.longitude, b.latitude)) < 50000\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY a.postalpostalcode ORDER BY distance ASC) = 1;\n",
    "\"\"\"\n",
    "\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "    CREATE OR REPLACE TABLE zip_code_weather_data_temp AS\n",
    "           SELECT \n",
    "            a.postalpostalcode,\n",
    "            b.date,\n",
    "            b.value as Max_Temp,\n",
    "            b.variable\n",
    "            FROM ELT_PROJECT_DATABASE.CSV_SCHEMA.zip_weather_station_mapping_temp a\n",
    "            JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_metrics_timeseries b\n",
    "            ON a.station_id = b.noaa_weather_station_id\n",
    "            WHERE b.variable = 'maximum_temperature';\n",
    "\"\"\"\n",
    "\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE TABLE supplier_zip_code_weather_temp2 AS \n",
    "SELECT a.PostalPostalCode, b.date, b.Max_temp FROM supplier_case as a\n",
    "JOIN zip_code_weather_data_temp as b ON a.postalpostalcode = b.postalpostalcode\n",
    "ORDER BY DATE;\n",
    "\"\"\"\n",
    "\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE TABLE supplier_zip_code_weather_temp AS \n",
    "SELECT A.PostalPostalCode, B.date, B.Max_temp FROM supplier_case as A\n",
    "LEFT JOIN zip_weather_data as B ON A.postalpostalcode = B.postalpostalcode\n",
    "ORDER BY DATE;\n",
    "\"\"\"\n",
    "cs.execute(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"CREATE OR REPLACE MATERIALIZED VIEW supplier_zip_code_weather AS (SELECT * FROM supplier_zip_code_weather_temp);\"\"\"\n",
    "\n",
    "cs.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Join purchase_orders_and_invoices, supplier_case, and supplier_zip_code_weather\n",
    "Based on zip \n",
    "codes and the transaction date. Only include transactions that have matching temperature readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff571b1d50>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW order_zip_temp AS \n",
    "SELECT \n",
    "    a.*, \n",
    "    b.SUPPLIERID AS SupplierID1, \n",
    "    c.SUPPLIERID AS SupplierID2\n",
    "FROM \n",
    "    supplier_zip_code_weather AS a\n",
    "LEFT JOIN \n",
    "    supplier_purchases AS b \n",
    "    ON a.date = b.OrderDate  \n",
    "LEFT JOIN \n",
    "    supplier_case AS C \n",
    "    ON a.postalpostalcode = c.postalpostalcode  \n",
    "WHERE \n",
    "    a.max_temp IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "cs.execute(command)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
